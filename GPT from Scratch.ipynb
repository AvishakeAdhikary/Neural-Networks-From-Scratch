{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9b417b-c07f-4ff7-bf54-dd89f05626ba",
   "metadata": {},
   "source": [
    "# Welcome to GPT from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35e52d-ea1b-4e9a-89ee-55b892e9d40f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Things to discuss before starting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b496593-73b0-4847-9abc-6a5d19e67d9e",
   "metadata": {},
   "source": [
    "This notebook is a continuation of my previous notebooks in order:\n",
    "1. <a href=\"https://github.com/AvishakeAdhikary/Neural-Networks-From-Scratch/blob/main/Neural%20Network%20with%20Derivatives.ipynb\">Neural Networks with Derivatives</a>\n",
    "2. <a href=\"https://github.com/AvishakeAdhikary/Neural-Networks-From-Scratch/blob/main/NameWeave.ipynb\">NameWeave</a>\n",
    "3. <a href=\"https://github.com/AvishakeAdhikary/Neural-Networks-From-Scratch/blob/main/NameWeave%20-%20Multi%20Layer%20Perceptron.ipynb\">NameWeave - Multi Layer Perceptron</a>\n",
    "4. <a href=\"https://github.com/AvishakeAdhikary/Neural-Networks-From-Scratch/blob/main/NameWeave%20(MLP)%20-%20Activations%2C%20Gradients%20%26%20Batch%20Normalization.ipynb\">NameWeave (MLP) - Activations, Gradients & Batch Normalization</a>\n",
    "5. <a href=\"https://github.com/AvishakeAdhikary/Neural-Networks-From-Scratch/blob/main/NameWeave%20-%20Manual%20Back%20Propagation.ipynb\">NameWeave - Manual Back Propagation</a>\n",
    "6. <a href=\"https://github.com/AvishakeAdhikary/Neural-Networks-From-Scratch/blob/main/NameWeave%20-%20WaveNet.ipynb\">NameWeave - WaveNet</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b91d8-8d4b-498f-8932-8c8b8506087e",
   "metadata": {},
   "source": [
    "Which means, I will be using a lot of the terminologies, explanations, and code from the previous notebooks that I have created in the series...\n",
    "\n",
    "And we will gradually build a complete **GPT** from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff5339-c626-48e0-9135-cb81cfa60d57",
   "metadata": {},
   "source": [
    "This notebook will be a little bit different from the previous notebooks that I have created previously and I will discuss the changes in a bit..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a5bb2-04a6-4442-ba16-9f36a2b2eafc",
   "metadata": {},
   "source": [
    "We will use a completely new dataset `Harry_Potter_Books.txt` which is a combined raw text of all the Harry Potter books by J. K. Rowling combined into a single `text` file, instead of `Indian_Names.txt` which we have used in the previous notebooks that contained Indian Firstnames crawled from a website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a01b1-4c47-4a51-8e74-33fb867f41f2",
   "metadata": {},
   "source": [
    "We will also keep softwares like <a href=\"https://chat.openai.com/\">ChatGPT</a>, <a href=\"https://gemini.google.com/app\">Google Gemini</a>, and other Large Language Models (LLM's) in mind and create our own little **Generative Pre-Trained Transformer (GPT)**...\n",
    "\n",
    "And you would probably know by now what these models are and what they do...\n",
    "\n",
    "Our **GPT** is going to be a *character level language model*, instead of a *sub-word-tokenized model* which softwares like ChatGPT and Google Gemini use in their models, and we will discuss everything in a bit...\n",
    "\n",
    "And we will not write all the `TORCH.NN` modules from scratch now, because we have already covered the most important ones already in our previous notebooks, instead we will implement the networks based on `TORCH.NN` library from PyTorch...\n",
    "\n",
    "And most importantly we will start from the simplest model (Bigram Model) and modify the same model within the same notebook and make our way upto the entire `Transformer` architecture...\n",
    "\n",
    "I have created an entire folder as `GPT Scripts` in the root of this repository to save each script for you to run them without even having to use jupyter notebooks. Rather you can simple use the `<filename>.py` to run each model to see how they perform on the same dataset as we move up, using:\n",
    "```bash\n",
    "python <filename>.py\n",
    "```\n",
    "\n",
    "So, it's going to me a long journey and it if going to be legen...wait-for-it...dary. Legendary!!!\\\n",
    "![Barney Stinson Wink](https://media.tenor.com/nJ3EeUPhVKkAAAAM/barny-stinson.gif)\n",
    "\n",
    "So let's get started..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6b5a45-f476-4f09-a2dd-ecef880a9205",
   "metadata": {},
   "source": [
    "# Understanding GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d72da0-a8c5-4180-bdf4-3bedef669acd",
   "metadata": {},
   "source": [
    "So what is a **GPT**?\n",
    "\n",
    "Well, **GPT** expands for the terminology as **Generative Pre-Trained Transformer**.\n",
    "\n",
    "You see how it consists of three words?\n",
    "\n",
    "Let's look at it in context of each word:\n",
    "1. Generative → Generates New Content\n",
    "2. Pre-Trained → Pre-trained on a dataset\n",
    "3. Transformer → Transformer architecture is being followed to make up the model (Don't worry we will discuss this later)\n",
    "\n",
    "That was easy..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e1d95f-acec-487c-84f0-07262f7b7274",
   "metadata": {},
   "source": [
    "Let's understand what **GPT** can do currently...\n",
    "\n",
    "Let's take `ChatGPT` as an example as of now and let's see it's capabilities...\n",
    "\n",
    "![ChatGPT Current Capabilities](https://miro.medium.com/v2/resize:fit:679/1*_3AM0Yhc7qgCvZ_X1L8mhw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40702e51-6551-4716-8635-83d3a6b6ab12",
   "metadata": {},
   "source": [
    "We see that `GPT` goes from left to right and generates text sequentially..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed61b3-940e-4429-939d-b24ddc022472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
